{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JoeyNMT-embeddings.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIpLyJ+hLcCnmbdSjD1ryt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliakreutzer/joeynmt-utils/blob/master/JoeyNMT_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzj-bzhAp7ws",
        "colab_type": "text"
      },
      "source": [
        "#JoeyNMT Embeddings\n",
        "### Example code for getting the mapping from vocabulary tokens to embeddings for a JoeyNMT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B31_jr8mqOGO",
        "colab_type": "text"
      },
      "source": [
        "First we install JoeyNMT and train a toy model. The toy model serves the technical demonstration purpose and is not very useful for analysis. Please replace it with your own trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr4M6vzLmmD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4f9955c-ce72-4438-a8b8-61db85f8ca63"
      },
      "source": [
        "!pip install joeynmt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joeynmt in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.6/dist-packages (from joeynmt) (2.5.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (49.1.0)\n",
            "Requirement already satisfied: subword-nmt in /usr/local/lib/python3.6/dist-packages (from joeynmt) (0.3.7)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from joeynmt) (7.0.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (1.5.1+cu101)\n",
            "Requirement already satisfied: six==1.12 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (1.12.0)\n",
            "Requirement already satisfied: wrapt==1.11.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (1.11.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from joeynmt) (0.3.1)\n",
            "Requirement already satisfied: sacrebleu>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (1.4.12)\n",
            "Requirement already satisfied: tensorflow>=1.14 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (2.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from joeynmt) (0.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from joeynmt) (0.10.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (1.18.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from joeynmt) (5.3.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from joeynmt) (3.2.2)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt) (0.10.1)\n",
            "Requirement already satisfied: mccabe<0.7,>=0.6 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt) (0.6.1)\n",
            "Requirement already satisfied: astroid<=2.5,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt) (2.4.2)\n",
            "Requirement already satisfied: isort<5,>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint->joeynmt) (4.3.21)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->joeynmt) (2.23.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt) (1.7.1)\n",
            "Requirement already satisfied: mecab-python3==0.996.5 in /usr/local/lib/python3.6/dist-packages (from sacrebleu>=1.3.6->joeynmt) (0.996.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (3.12.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (2.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (1.30.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (2.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.14->joeynmt) (0.34.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from seaborn->joeynmt) (1.0.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->joeynmt) (0.10.0)\n",
            "Requirement already satisfied: lazy-object-proxy==1.4.* in /usr/local/lib/python3.6/dist-packages (from astroid<=2.5,>=2.4.0->pylint->joeynmt) (1.4.3)\n",
            "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from astroid<=2.5,>=2.4.0->pylint->joeynmt) (1.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->joeynmt) (3.0.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (0.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.22.0->seaborn->joeynmt) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=1.14->joeynmt) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhDDnUqTnR85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "47fc0133-1144-4b9a-c829-76afff6e983f"
      },
      "source": [
        "!git clone https://github.com/joeynmt/joeynmt.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'joeynmt'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 2479 (delta 2), reused 0 (delta 0), pack-reused 2467\u001b[K\n",
            "Receiving objects: 100% (2479/2479), 2.65 MiB | 2.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1727/1727), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZE44sTpnmR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "65711674-0587-4f9b-b14b-4858ce9662a3"
      },
      "source": [
        "! cd joeynmt; python -m joeynmt train configs/small.yaml"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-30 02:50:39,435 Hello! This is Joey-NMT.\n",
            "2020-07-30 02:50:39.581776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-30 02:50:41,029 Total params: 66376\n",
            "2020-07-30 02:50:41,030 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_hh_l2', 'encoder.rnn.bias_hh_l2_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_ih_l2_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.weight_hh_l2_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_ih_l2_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
            "2020-07-30 02:50:41,031 cfg.name                           : my_experiment\n",
            "2020-07-30 02:50:41,031 cfg.data.src                       : de\n",
            "2020-07-30 02:50:41,031 cfg.data.trg                       : en\n",
            "2020-07-30 02:50:41,031 cfg.data.train                     : test/data/toy/train\n",
            "2020-07-30 02:50:41,031 cfg.data.dev                       : test/data/toy/dev\n",
            "2020-07-30 02:50:41,031 cfg.data.test                      : test/data/toy/test\n",
            "2020-07-30 02:50:41,031 cfg.data.random_train_subset       : -1\n",
            "2020-07-30 02:50:41,031 cfg.data.level                     : word\n",
            "2020-07-30 02:50:41,031 cfg.data.lowercase                 : True\n",
            "2020-07-30 02:50:41,031 cfg.data.max_sent_length           : 30\n",
            "2020-07-30 02:50:41,031 cfg.data.src_voc_min_freq          : 1\n",
            "2020-07-30 02:50:41,031 cfg.data.src_voc_limit             : 101\n",
            "2020-07-30 02:50:41,032 cfg.data.trg_voc_min_freq          : 1\n",
            "2020-07-30 02:50:41,032 cfg.data.trg_voc_limit             : 102\n",
            "2020-07-30 02:50:41,032 cfg.testing.beam_size              : 5\n",
            "2020-07-30 02:50:41,032 cfg.testing.alpha                  : 1.0\n",
            "2020-07-30 02:50:41,032 cfg.testing.postprocess            : True\n",
            "2020-07-30 02:50:41,032 cfg.training.reset_best_ckpt       : False\n",
            "2020-07-30 02:50:41,032 cfg.training.reset_scheduler       : False\n",
            "2020-07-30 02:50:41,032 cfg.training.reset_optimizer       : False\n",
            "2020-07-30 02:50:41,032 cfg.training.random_seed           : 42\n",
            "2020-07-30 02:50:41,032 cfg.training.optimizer             : adam\n",
            "2020-07-30 02:50:41,032 cfg.training.adam_betas            : [0.9, 0.999]\n",
            "2020-07-30 02:50:41,032 cfg.training.learning_rate         : 0.005\n",
            "2020-07-30 02:50:41,032 cfg.training.learning_rate_min     : 0.0001\n",
            "2020-07-30 02:50:41,032 cfg.training.clip_grad_val         : 1.0\n",
            "2020-07-30 02:50:41,032 cfg.training.weight_decay          : 0.0\n",
            "2020-07-30 02:50:41,033 cfg.training.batch_size            : 10\n",
            "2020-07-30 02:50:41,033 cfg.training.batch_type            : sentence\n",
            "2020-07-30 02:50:41,033 cfg.training.eval_batch_size       : 10\n",
            "2020-07-30 02:50:41,033 cfg.training.eval_batch_type       : sentence\n",
            "2020-07-30 02:50:41,033 cfg.training.batch_multiplier      : 1\n",
            "2020-07-30 02:50:41,033 cfg.training.normalization         : batch\n",
            "2020-07-30 02:50:41,033 cfg.training.scheduling            : plateau\n",
            "2020-07-30 02:50:41,033 cfg.training.patience              : 5\n",
            "2020-07-30 02:50:41,033 cfg.training.decrease_factor       : 0.5\n",
            "2020-07-30 02:50:41,033 cfg.training.epochs                : 1\n",
            "2020-07-30 02:50:41,033 cfg.training.validation_freq       : 10\n",
            "2020-07-30 02:50:41,033 cfg.training.logging_freq          : 10\n",
            "2020-07-30 02:50:41,033 cfg.training.eval_metric           : bleu\n",
            "2020-07-30 02:50:41,033 cfg.training.early_stopping_metric : loss\n",
            "2020-07-30 02:50:41,033 cfg.training.model_dir             : models/small_model\n",
            "2020-07-30 02:50:41,033 cfg.training.overwrite             : True\n",
            "2020-07-30 02:50:41,034 cfg.training.shuffle               : True\n",
            "2020-07-30 02:50:41,034 cfg.training.use_cuda              : False\n",
            "2020-07-30 02:50:41,034 cfg.training.max_output_length     : 31\n",
            "2020-07-30 02:50:41,034 cfg.training.print_valid_sents     : [0, 1, 2]\n",
            "2020-07-30 02:50:41,034 cfg.training.keep_last_ckpts       : 3\n",
            "2020-07-30 02:50:41,034 cfg.training.label_smoothing       : 0.0\n",
            "2020-07-30 02:50:41,034 cfg.model.initializer              : xavier\n",
            "2020-07-30 02:50:41,034 cfg.model.init_weight              : 0.01\n",
            "2020-07-30 02:50:41,034 cfg.model.init_gain                : 1.0\n",
            "2020-07-30 02:50:41,034 cfg.model.bias_initializer         : zeros\n",
            "2020-07-30 02:50:41,034 cfg.model.embed_initializer        : normal\n",
            "2020-07-30 02:50:41,034 cfg.model.embed_init_weight        : 0.1\n",
            "2020-07-30 02:50:41,034 cfg.model.embed_init_gain          : 1.0\n",
            "2020-07-30 02:50:41,034 cfg.model.init_rnn_orthogonal      : False\n",
            "2020-07-30 02:50:41,034 cfg.model.lstm_forget_gate         : 1.0\n",
            "2020-07-30 02:50:41,034 cfg.model.tied_embeddings          : False\n",
            "2020-07-30 02:50:41,035 cfg.model.tied_softmax             : False\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.type             : recurrent\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.rnn_type         : gru\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.embeddings.embedding_dim : 16\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.embeddings.scale : False\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.embeddings.freeze : False\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.hidden_size      : 30\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.bidirectional    : True\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.dropout          : 0.2\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.num_layers       : 3\n",
            "2020-07-30 02:50:41,035 cfg.model.encoder.freeze           : False\n",
            "2020-07-30 02:50:41,035 cfg.model.decoder.type             : recurrent\n",
            "2020-07-30 02:50:41,035 cfg.model.decoder.rnn_type         : gru\n",
            "2020-07-30 02:50:41,035 cfg.model.decoder.embeddings.embedding_dim : 16\n",
            "2020-07-30 02:50:41,035 cfg.model.decoder.embeddings.scale : False\n",
            "2020-07-30 02:50:41,035 cfg.model.decoder.embeddings.freeze : False\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.hidden_size      : 30\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.dropout          : 0.2\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.hidden_dropout   : 0.2\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.num_layers       : 2\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.input_feeding    : True\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.init_hidden      : last\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.attention        : bahdanau\n",
            "2020-07-30 02:50:41,036 cfg.model.decoder.freeze           : False\n",
            "2020-07-30 02:50:41,036 Data set sizes: \n",
            "\ttrain 922,\n",
            "\tvalid 20,\n",
            "\ttest 20\n",
            "2020-07-30 02:50:41,036 First training example:\n",
            "\t[SRC] david gallo: das ist bill lange. ich bin dave gallo.\n",
            "\t[TRG] david gallo: this is bill lange. i'm dave gallo.\n",
            "2020-07-30 02:50:41,036 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) und (5) die (6) wir (7) der (8) sie (9) das\n",
            "2020-07-30 02:50:41,037 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) the (5) and (6) of (7) to (8) a (9) in\n",
            "2020-07-30 02:50:41,037 Number of Src words (types): 105\n",
            "2020-07-30 02:50:41,037 Number of Trg words (types): 106\n",
            "2020-07-30 02:50:41,037 Model(\n",
            "\tencoder=RecurrentEncoder(GRU(16, 30, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)),\n",
            "\tdecoder=RecurrentDecoder(rnn=GRU(46, 30, num_layers=2, batch_first=True, dropout=0.2), attention=BahdanauAttention),\n",
            "\tsrc_embed=Embeddings(embedding_dim=16, vocab_size=105),\n",
            "\ttrg_embed=Embeddings(embedding_dim=16, vocab_size=106))\n",
            "2020-07-30 02:50:41,038 EPOCH 1\n",
            "2020-07-30 02:50:41,750 Epoch   1 Step:       10 Batch Loss:    19.871571 Tokens per Sec:     1453, Lr: 0.005000\n",
            "2020-07-30 02:50:41,919 Hooray! New best validation result [loss]!\n",
            "2020-07-30 02:50:41,919 Saving new checkpoint.\n",
            "2020-07-30 02:50:41,925 Example #0\n",
            "2020-07-30 02:50:41,925 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:41,925 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:41,925 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:41,925 Example #1\n",
            "2020-07-30 02:50:41,925 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:41,925 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:41,926 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:41,926 Example #2\n",
            "2020-07-30 02:50:41,926 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:41,926 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:41,926 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:41,926 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 1045.0957, ppl:  15.8759, duration: 0.1752s\n",
            "2020-07-30 02:50:44,099 Epoch   1 Step:       20 Batch Loss:    21.683571 Tokens per Sec:      708, Lr: 0.005000\n",
            "2020-07-30 02:50:44,270 Hooray! New best validation result [loss]!\n",
            "2020-07-30 02:50:44,270 Saving new checkpoint.\n",
            "2020-07-30 02:50:44,275 Example #0\n",
            "2020-07-30 02:50:44,275 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:44,275 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:44,275 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:44,275 Example #1\n",
            "2020-07-30 02:50:44,275 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:44,275 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:44,275 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:44,276 Example #2\n",
            "2020-07-30 02:50:44,276 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:44,276 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:44,276 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:44,276 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 999.4313, ppl:  14.0693, duration: 0.1767s\n",
            "2020-07-30 02:50:46,326 Epoch   1 Step:       30 Batch Loss:    32.438263 Tokens per Sec:      723, Lr: 0.005000\n",
            "2020-07-30 02:50:46,485 Hooray! New best validation result [loss]!\n",
            "2020-07-30 02:50:46,485 Saving new checkpoint.\n",
            "2020-07-30 02:50:46,489 Example #0\n",
            "2020-07-30 02:50:46,489 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:46,490 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:46,490 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:46,490 Example #1\n",
            "2020-07-30 02:50:46,490 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:46,490 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:46,490 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:46,490 Example #2\n",
            "2020-07-30 02:50:46,490 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:46,490 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:46,490 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:46,490 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 994.4028, ppl:  13.8834, duration: 0.1643s\n",
            "2020-07-30 02:50:48,621 Epoch   1 Step:       40 Batch Loss:    39.462688 Tokens per Sec:      699, Lr: 0.005000\n",
            "2020-07-30 02:50:48,776 Example #0\n",
            "2020-07-30 02:50:48,777 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:48,777 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:48,777 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:48,777 Example #1\n",
            "2020-07-30 02:50:48,777 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:48,777 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:48,777 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:48,777 Example #2\n",
            "2020-07-30 02:50:48,777 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:48,777 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:48,778 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:48,778 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 999.0395, ppl:  14.0548, duration: 0.1560s\n",
            "2020-07-30 02:50:50,701 Epoch   1 Step:       50 Batch Loss:     8.803011 Tokens per Sec:      578, Lr: 0.005000\n",
            "2020-07-30 02:50:50,854 Example #0\n",
            "2020-07-30 02:50:50,855 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:50,855 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:50,855 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:50,855 Example #1\n",
            "2020-07-30 02:50:50,855 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:50,855 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:50,855 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:50,855 Example #2\n",
            "2020-07-30 02:50:50,855 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:50,855 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:50,855 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:50,855 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 1002.5289, ppl:  14.1851, duration: 0.1541s\n",
            "2020-07-30 02:50:52,798 Epoch   1 Step:       60 Batch Loss:    32.723629 Tokens per Sec:      670, Lr: 0.005000\n",
            "2020-07-30 02:50:52,951 Hooray! New best validation result [loss]!\n",
            "2020-07-30 02:50:52,951 Saving new checkpoint.\n",
            "2020-07-30 02:50:52,956 Example #0\n",
            "2020-07-30 02:50:52,956 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:52,956 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:52,956 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:52,956 Example #1\n",
            "2020-07-30 02:50:52,956 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:52,956 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:52,957 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:52,957 Example #2\n",
            "2020-07-30 02:50:52,957 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:52,957 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:52,957 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:52,957 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 992.4550, ppl:  13.8121, duration: 0.1583s\n",
            "2020-07-30 02:50:55,108 Epoch   1 Step:       70 Batch Loss:    53.196281 Tokens per Sec:      638, Lr: 0.005000\n",
            "2020-07-30 02:50:55,270 Example #0\n",
            "2020-07-30 02:50:55,271 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:55,271 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:55,271 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:55,271 Example #1\n",
            "2020-07-30 02:50:55,271 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:55,271 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:55,271 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:55,271 Example #2\n",
            "2020-07-30 02:50:55,271 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:55,271 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:55,271 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:55,271 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 1002.3389, ppl:  14.1780, duration: 0.1635s\n",
            "2020-07-30 02:50:57,345 Epoch   1 Step:       80 Batch Loss:    48.362408 Tokens per Sec:      669, Lr: 0.005000\n",
            "2020-07-30 02:50:57,500 Hooray! New best validation result [loss]!\n",
            "2020-07-30 02:50:57,500 Saving new checkpoint.\n",
            "2020-07-30 02:50:57,505 Example #0\n",
            "2020-07-30 02:50:57,505 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:57,505 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:57,505 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:57,505 Example #1\n",
            "2020-07-30 02:50:57,505 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:57,505 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:57,505 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:57,506 Example #2\n",
            "2020-07-30 02:50:57,506 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:57,506 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:57,506 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:57,506 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 987.8223, ppl:  13.6438, duration: 0.1608s\n",
            "2020-07-30 02:50:59,632 Epoch   1 Step:       90 Batch Loss:    41.305519 Tokens per Sec:      684, Lr: 0.005000\n",
            "2020-07-30 02:50:59,785 Example #0\n",
            "2020-07-30 02:50:59,786 \tSource:     ich freue mich , dass ich da bin .\n",
            "2020-07-30 02:50:59,786 \tReference:  i’m happy to be here .\n",
            "2020-07-30 02:50:59,786 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:59,786 Example #1\n",
            "2020-07-30 02:50:59,786 \tSource:     ja , guten tag .\n",
            "2020-07-30 02:50:59,786 \tReference:  yes , hello .\n",
            "2020-07-30 02:50:59,786 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:59,786 Example #2\n",
            "2020-07-30 02:50:59,786 \tSource:     ja , also , was soll biohacking sein ?\n",
            "2020-07-30 02:50:59,786 \tReference:  yes , so , what is biohacking ?\n",
            "2020-07-30 02:50:59,787 \tHypothesis: <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
            "2020-07-30 02:50:59,787 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 1000.0751, ppl:  14.0933, duration: 0.1543s\n",
            "2020-07-30 02:51:01,420 Epoch   1: total training loss 3845.91\n",
            "2020-07-30 02:51:01,421 Training ended after   1 epochs.\n",
            "2020-07-30 02:51:01,421 Best validation result (greedy) at step       80: 987.82 loss.\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "2020-07-30 02:51:01,672  dev bleu:   0.00 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
            "2020-07-30 02:51:01,672 Translations saved to: models/small_model/00000080.hyps.dev\n",
            "2020-07-30 02:51:01,816 No references given for test -> no evaluation.\n",
            "2020-07-30 02:51:01,816 Translations saved to: models/small_model/00000080.hyps.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2hiYYekqTOL",
        "colab_type": "text"
      },
      "source": [
        "All we need is stored in the model directory: checkpoints, vocabulary and the log which helps us find the variable name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG31_P4rnoAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "c1d0ffaa-15b3-4acb-ee1d-f07c3ff8cc94"
      },
      "source": [
        "model_dir = 'joeynmt/models/small_model/'\n",
        "! ls $model_dir"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00000080.hyps.dev   70.hyps\t  att.30.0.pdf\tatt.60.1.pdf  att.90.2.pdf\n",
            "00000080.hyps.test  80.ckpt\t  att.30.1.pdf\tatt.60.2.pdf  best.ckpt\n",
            "10.hyps\t\t    80.hyps\t  att.30.2.pdf\tatt.70.0.pdf  config.yaml\n",
            "20.hyps\t\t    90.hyps\t  att.40.0.pdf\tatt.70.1.pdf  src_vocab.txt\n",
            "30.ckpt\t\t    att.10.0.pdf  att.40.1.pdf\tatt.70.2.pdf  tensorboard\n",
            "30.hyps\t\t    att.10.1.pdf  att.40.2.pdf\tatt.80.0.pdf  train.log\n",
            "40.hyps\t\t    att.10.2.pdf  att.50.0.pdf\tatt.80.1.pdf  trg_vocab.txt\n",
            "50.hyps\t\t    att.20.0.pdf  att.50.1.pdf\tatt.80.2.pdf  validations.txt\n",
            "60.ckpt\t\t    att.20.1.pdf  att.50.2.pdf\tatt.90.0.pdf\n",
            "60.hyps\t\t    att.20.2.pdf  att.60.0.pdf\tatt.90.1.pdf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQzCtiViqhXe",
        "colab_type": "text"
      },
      "source": [
        "In the log we find the variable names in the \"Trainable parameters\" list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_O2mAdanvtY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "34cb6003-2964-4078-873d-b67d40445ab0"
      },
      "source": [
        "! head $model_dir/train.log"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-30 02:50:39,435 Hello! This is Joey-NMT.\n",
            "2020-07-30 02:50:41,029 Total params: 66376\n",
            "2020-07-30 02:50:41,030 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_hh_l2', 'encoder.rnn.bias_hh_l2_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_ih_l2_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.weight_hh_l2_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_ih_l2_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
            "2020-07-30 02:50:41,031 cfg.name                           : my_experiment\n",
            "2020-07-30 02:50:41,031 cfg.data.src                       : de\n",
            "2020-07-30 02:50:41,031 cfg.data.trg                       : en\n",
            "2020-07-30 02:50:41,031 cfg.data.train                     : test/data/toy/train\n",
            "2020-07-30 02:50:41,031 cfg.data.dev                       : test/data/toy/dev\n",
            "2020-07-30 02:50:41,031 cfg.data.test                      : test/data/toy/test\n",
            "2020-07-30 02:50:41,031 cfg.data.random_train_subset       : -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuxyvpoOqqzS",
        "colab_type": "text"
      },
      "source": [
        "We choose which checkpoint to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P2dDhz-oiIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_embed_name = 'src_embed.lut.weight'\n",
        "trg_embed_name = 'trg_embed.lut.weight'\n",
        "ckpt_path = model_dir+'80.ckpt'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlxbthXwq2O-",
        "colab_type": "text"
      },
      "source": [
        "Now we load the checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axx2TwMUonhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SdjCGUqovAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state = torch.load(\n",
        "            ckpt_path,\n",
        "            map_location=(\n",
        "                lambda s, _: torch.serialization.default_restore_location(\n",
        "                    s, 'cpu')\n",
        "            ),\n",
        "        )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asqJSWEEq6mK",
        "colab_type": "text"
      },
      "source": [
        "The state is a dictionary that contains all kinds of information, e.g. the state of the learning state scheduler and the optimizer, but also all model variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkAdRLWRo1Vo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "544aac5a-f208-4429-8612-012410fc84b5"
      },
      "source": [
        "state.keys()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['steps', 'total_tokens', 'best_ckpt_score', 'best_ckpt_iteration', 'model_state', 'optimizer_state', 'scheduler_state'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPRWmAw-rYca",
        "colab_type": "text"
      },
      "source": [
        "The model variables are stored in `model_state`, which in turns contains an ordered dictionaries mapping all variable names to their tensors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wtaj5CW0o2EG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params = state['model_state']"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgYU1G-mo7q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b8499d15-9c0f-4ad1-d4bc-8d0288ceb556"
      },
      "source": [
        "model_params.keys()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['src_embed.lut.weight', 'trg_embed.lut.weight', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.weight_ih_l1_reverse', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.weight_ih_l2', 'encoder.rnn.weight_hh_l2', 'encoder.rnn.bias_ih_l2', 'encoder.rnn.bias_hh_l2', 'encoder.rnn.weight_ih_l2_reverse', 'encoder.rnn.weight_hh_l2_reverse', 'encoder.rnn.bias_ih_l2_reverse', 'encoder.rnn.bias_hh_l2_reverse', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.weight_ih_l1', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.bias_hh_l1', 'decoder.att_vector_layer.weight', 'decoder.att_vector_layer.bias', 'decoder.output_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.attention.energy_layer.weight'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD1sVlTfrxIB",
        "colab_type": "text"
      },
      "source": [
        "Let's get those embedding tensors into numpy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvKwmo3Ao9BH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_embed_np = model_params[src_embed_name].numpy()\n",
        "trg_embed_np = model_params[trg_embed_name].numpy()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUjNG2HYr3SB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "a376064d-7080-49ff-d7a5-54b0f52783d3"
      },
      "source": [
        "src_embed_np"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04882606,  0.27952445, -0.17270268, ...,  0.08273638,\n",
              "         0.11830907, -0.09549082],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.14481221,  0.02316462,  0.08613672, ...,  0.08579643,\n",
              "        -0.17944561, -0.0809639 ],\n",
              "       ...,\n",
              "       [-0.11935379, -0.01926058,  0.00690783, ..., -0.07890854,\n",
              "         0.15513302,  0.04006948],\n",
              "       [-0.0792576 ,  0.01266935,  0.01000918, ...,  0.06186913,\n",
              "        -0.1043992 ,  0.08111023],\n",
              "       [ 0.19373532,  0.12218103, -0.04352958, ..., -0.11677602,\n",
              "         0.02940773, -0.19825104]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2OlQfLVr52e",
        "colab_type": "text"
      },
      "source": [
        "Now we just need to map the rows of the embedding matrices to the tokens in the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjCL0Ut5pAzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "36f69908-8604-4b3f-8674-c09ba7cba71a"
      },
      "source": [
        "print('src embedding shape:', src_embed_np.shape)\n",
        "print('trg embedding shape:', trg_embed_np.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src embedding shape: (105, 16)\n",
            "trg embedding shape: (106, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfoiuGTvpInk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b5a0ae96-7d2d-4c84-acdf-c1cb875020cd"
      },
      "source": [
        "src_vocab_file = model_dir+'src_vocab.txt'\n",
        "trg_vocab_file = model_dir+'trg_vocab.txt'\n",
        "! wc -l $src_vocab_file\n",
        "! wc -l $trg_vocab_file"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "105 joeynmt/models/small_model/src_vocab.txt\n",
            "106 joeynmt/models/small_model/trg_vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi9Whk5AsB_l",
        "colab_type": "text"
      },
      "source": [
        "Luckily, this mapping is encoded in the vocabulary files stored in the model directory. Lines in that file correspond to rows in the embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-z7ccahpY_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_tokens = []\n",
        "with open(src_vocab_file, 'r') as of:\n",
        "  for line in of: \n",
        "    src_tokens.append(line.strip())"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqZQR-FpsNS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trg_tokens = []\n",
        "with open(trg_vocab_file, 'r') as of:\n",
        "  for line in of: \n",
        "    trg_tokens.append(line.strip())"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByWPTLe2pxzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "68d7a9a7-c6a7-4929-bc4d-bd98b8fd22d6"
      },
      "source": [
        "src_tokens"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<s>',\n",
              " '</s>',\n",
              " 'und',\n",
              " 'die',\n",
              " 'wir',\n",
              " 'der',\n",
              " 'sie',\n",
              " 'das',\n",
              " 'ist',\n",
              " 'in',\n",
              " 'es',\n",
              " 'ich',\n",
              " 'zu',\n",
              " 'nicht',\n",
              " 'von',\n",
              " 'ein',\n",
              " 'eine',\n",
              " 'wie',\n",
              " 'mit',\n",
              " 'den',\n",
              " 'dass',\n",
              " 'aber',\n",
              " 'was',\n",
              " 'sich',\n",
              " 'auf',\n",
              " 'für',\n",
              " 'sind',\n",
              " 'im',\n",
              " 'so',\n",
              " 'diese',\n",
              " 'dem',\n",
              " 'haben',\n",
              " 'hier',\n",
              " 'uns',\n",
              " 'als',\n",
              " 'man',\n",
              " 'spielen',\n",
              " 'des',\n",
              " 'werden',\n",
              " 'über',\n",
              " '–',\n",
              " 'um',\n",
              " 'oder',\n",
              " 'an',\n",
              " 'sehr',\n",
              " '--',\n",
              " 'nur',\n",
              " 'wenn',\n",
              " 'aus',\n",
              " 'also',\n",
              " 'ihnen',\n",
              " 'einen',\n",
              " 'hat',\n",
              " 'dieser',\n",
              " 'einer',\n",
              " 'ist,',\n",
              " 'ist.',\n",
              " 'nach',\n",
              " 'dies',\n",
              " 'er',\n",
              " 'können',\n",
              " 'war',\n",
              " 'auch',\n",
              " 'einem',\n",
              " 'habe',\n",
              " 'kann',\n",
              " 'noch',\n",
              " 'sehen',\n",
              " 'zum',\n",
              " 'ihre',\n",
              " 'weil',\n",
              " 'am',\n",
              " 'ihren',\n",
              " 'wird',\n",
              " 'bis',\n",
              " 'dann',\n",
              " 'keine',\n",
              " 'mehr',\n",
              " 'gibt',\n",
              " 'alle',\n",
              " 'mich',\n",
              " 'mir',\n",
              " 'ohne',\n",
              " 'schüler',\n",
              " 'lehrer',\n",
              " 'letzten',\n",
              " 'länder',\n",
              " 'mein',\n",
              " 'sind.',\n",
              " 'spielen.',\n",
              " 'welt',\n",
              " 'alles',\n",
              " 'bei',\n",
              " 'ihr',\n",
              " 'leute',\n",
              " 'unser',\n",
              " 'zwei',\n",
              " 'kinder',\n",
              " 'unsere',\n",
              " 'andere',\n",
              " 'brauchen',\n",
              " 'da',\n",
              " 'haben,']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6RQjSj5pzon",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc889390-8773-45b8-a380-0dc50adcf48e"
      },
      "source": [
        "trg_tokens"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<s>',\n",
              " '</s>',\n",
              " 'the',\n",
              " 'and',\n",
              " 'of',\n",
              " 'to',\n",
              " 'a',\n",
              " 'in',\n",
              " 'that',\n",
              " 'we',\n",
              " 'you',\n",
              " 'is',\n",
              " 'i',\n",
              " 'it',\n",
              " 'this',\n",
              " \"it's\",\n",
              " 'they',\n",
              " 'what',\n",
              " 'but',\n",
              " 'are',\n",
              " 'have',\n",
              " 'on',\n",
              " '--',\n",
              " 'for',\n",
              " 'so',\n",
              " 'with',\n",
              " 'not',\n",
              " 'at',\n",
              " 'can',\n",
              " 'as',\n",
              " 'how',\n",
              " 'about',\n",
              " 'be',\n",
              " 'do',\n",
              " 'like',\n",
              " 'these',\n",
              " 'was',\n",
              " 'all',\n",
              " 'one',\n",
              " 'going',\n",
              " 'our',\n",
              " 'from',\n",
              " 'people',\n",
              " 'see',\n",
              " 'their',\n",
              " \"we're\",\n",
              " 'my',\n",
              " 'very',\n",
              " 'just',\n",
              " 'would',\n",
              " \"don't\",\n",
              " \"i'm\",\n",
              " 'or',\n",
              " 'some',\n",
              " 'play',\n",
              " 'by',\n",
              " 'if',\n",
              " 'out',\n",
              " 'there',\n",
              " 'when',\n",
              " 'your',\n",
              " 'because',\n",
              " \"that's\",\n",
              " 'up',\n",
              " 'here',\n",
              " 'play.',\n",
              " 'an',\n",
              " 'had',\n",
              " 'into',\n",
              " 'look',\n",
              " 'most',\n",
              " 'need',\n",
              " 'really',\n",
              " 'could',\n",
              " 'two',\n",
              " \"you're\",\n",
              " 'countries',\n",
              " 'get',\n",
              " 'has',\n",
              " 'little',\n",
              " 'lot',\n",
              " 'now',\n",
              " 'where',\n",
              " 'actually',\n",
              " 'them',\n",
              " 'those',\n",
              " 'want',\n",
              " 'were',\n",
              " 'world',\n",
              " 'more',\n",
              " 'us',\n",
              " 'which',\n",
              " 'back',\n",
              " 'been',\n",
              " 'every',\n",
              " 'it.',\n",
              " 'last',\n",
              " 'make',\n",
              " 'much',\n",
              " 'teachers',\n",
              " \"there's\",\n",
              " \"they're\",\n",
              " \"what's\",\n",
              " 'also']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-DFuEuLt0MD",
        "colab_type": "text"
      },
      "source": [
        "Let's combine them into a dictionary for convenience."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69__FKeGsh_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_lookup = dict()\n",
        "for src_token, src_embedding in zip(src_tokens, src_embed_np):\n",
        "  src_lookup[src_token] = src_embedding"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibGsylesxzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trg_lookup = dict()\n",
        "for trg_token, trg_embedding in zip(trg_tokens, trg_embed_np):\n",
        "  trg_lookup[trg_token] = trg_embedding"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaW_tE8Jt4Gq",
        "colab_type": "text"
      },
      "source": [
        "Now we can access all the embeddings for the entries in the vocabularies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9bMsw1rs3T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "2a0cfea0-ea20-424e-acc9-26d7bc567674"
      },
      "source": [
        "src_lookup['und']"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.14950925,  0.16700658,  0.06261288,  0.1259178 , -0.04032829,\n",
              "        0.12182242,  0.00768116,  0.16330443,  0.01679206,  0.18671978,\n",
              "       -0.05414075, -0.09371719,  0.04571239, -0.17080298, -0.08591209,\n",
              "       -0.03932576], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Ut5W7Es8Te",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "04464231-d0f8-46cd-e5f2-2d61a3bf1afc"
      },
      "source": [
        "trg_lookup['and']"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.09322029,  0.02723755, -0.03550061, -0.12619726, -0.15012138,\n",
              "       -0.05097466,  0.051622  , -0.0485785 , -0.02459926, -0.03740474,\n",
              "       -0.06900709,  0.10374887, -0.02208178,  0.12240209,  0.18867075,\n",
              "       -0.1501357 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLu4hTiPt9Gv",
        "colab_type": "text"
      },
      "source": [
        "And we can do arbitrary calculations or visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0hvurhXs-OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyiHaioCtAqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "95b1d5eb-59f7-4816-9709-7093b2f2a776"
      },
      "source": [
        "np.dot(src_lookup['und'], trg_lookup['and'])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0807992"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE4DWDpGtO6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIwTYDkItWlt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "c5f958dd-ed76-4b54-debf-7190f2f3635b"
      },
      "source": [
        "plt.imshow(np.expand_dims(src_lookup['und'], 0))\n",
        "plt.show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2I48MICtY7c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "58ca2378-5034-4b8e-fab5-48e0cd77cbc5"
      },
      "source": [
        "plt.imshow(np.expand_dims(trg_lookup['and'], 0))\n",
        "plt.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDNuNBZztyMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}